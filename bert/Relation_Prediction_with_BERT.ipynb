{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Prediction in Argument Mining with Pre-trained Deep Bidirectional Transformers\n",
    "\n",
    "Code for BA thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import os \n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "from bert import modeling\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_data(filename, data):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    print(df.groupby('org_dataset').org.apply(lambda x: x.str.split().str.len().mean()))\n",
    "    print(df.groupby('org_dataset').response.apply(lambda x: x.str.split().str.len().mean()))\n",
    "    # Split in Training and Validation data\n",
    "    if data == 'node':\n",
    "        # Training data: NoDe debatepedia all versions without neutral label\n",
    "        # Validation data: NoDe procon\n",
    "        dataset = df.loc[~df['org_dataset'].isin(['political', 'comargGM', 'comargUGIP', 'agreement'])]\n",
    "        dataset = df.loc[df['org_dataset'].isin(['debate_test', 'debate_train', 'procon'])] # Use orignal data\n",
    "        # dataset = dataset[dataset['label'] != 'unrelated'] # Filter only support/attack\n",
    "        dataset = dataset.sample(frac=1)\n",
    "        #data_train = dataset.iloc[:-100]\n",
    "        #data_val = dataset #.iloc[-100:]\n",
    "        data_train = dataset.loc[~dataset['org_dataset'].isin(['debate_test'])]\n",
    "        data_val = dataset.loc[dataset['org_dataset'].isin(['debate_test'])]\n",
    "    elif data == 'political':\n",
    "        dataset = df.loc[df['org_dataset'].isin(['political'])]\n",
    "        #dataset = dataset[dataset['label'] != 'unrelated'] # Filter only support/attack\n",
    "        dataset = dataset.sample(frac=1)\n",
    "        data_train = dataset.iloc[:-200]\n",
    "        data_val = dataset.iloc[-200:]\n",
    "    elif data == 'agreement':\n",
    "        dataset = df.loc[df['org_dataset'].isin(['agreement'])]\n",
    "        dataset = dataset.sample(frac=1).dropna()\n",
    "        data_train = dataset.iloc[:-2000]\n",
    "        data_val = dataset.iloc[-2000:]\n",
    "    else:\n",
    "        print('Invalid dataset')\n",
    "        sys.exit(-1)\n",
    "    return data_train, data_val\n",
    "\n",
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "    \n",
    "    is_training = not is_predicting\n",
    "    \n",
    "    \"\"\"\n",
    "    model = modeling.BertModel(\n",
    "        config=BERT_CONFIG,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=False)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = model.get_pooled_output()\n",
    "    \n",
    "    \"\"\"\n",
    "    tags = set()\n",
    "    if is_training:\n",
    "        tags.add(\"train\")\n",
    "    bert_module = hub.Module(\n",
    "        BERT_MODEL_HUB,\n",
    "        tags=tags,\n",
    "        trainable=True)\n",
    "    bert_inputs = dict(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "        inputs=bert_inputs,\n",
    "        signature=\"tokens\",\n",
    "        as_dict=True)\n",
    "    \n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "    \n",
    "    #######\n",
    "    \n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02, seed=0))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if is_training:\n",
    "            # Dropout helps prevent overfitting\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9, seed=1)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)\n",
    "\n",
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "    \n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN \n",
    "        if not is_predicting:\n",
    "\n",
    "            (loss, predicted_labels, log_probs) = create_model(\n",
    "                is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = optimization.create_optimizer(\n",
    "              loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                  loss=loss,\n",
    "                  train_op=train_op)\n",
    "\n",
    "        # TEST\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(\n",
    "                is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {\n",
    "                'probabilities': log_probs,\n",
    "                'labels': predicted_labels\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All parameters\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # Deactivate GPU for testing stability\n",
    "\n",
    "cross_val = False\n",
    "data_path = '../data/complete_data.tsv'\n",
    "dataset = 'node'  # One of 'agreement', 'node' and 'political'\n",
    "use_org = True\n",
    "use_resp = True\n",
    "convert_dicts = {'agreement': {\"agreement\": 0, \"disagreement\": 1, \"unrelated\": 2},\n",
    "                'node': {\"attack\": 0, \"support\": 1, \"unrelated\": 2},\n",
    "                'political': {\"attack\": 0, \"support\": 0, \"unrelated\": 1}}\n",
    "                #'political': {\"attack\": 0, \"support\": 1, \"unrelated\": 1}}\n",
    "convert_dict = convert_dicts[dataset]\n",
    "\n",
    "ORG_COLUMN = 'org'\n",
    "RESP_COLUMN = 'response'\n",
    "LABEL_COLUMN = 'label'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1] # [0, 1, 2]\n",
    "BERT_VOCAB= './uncased_L-12_H-768_A-12/vocab.txt'\n",
    "BERT_INIT_CHKPNT = './uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "BERT_CONFIG_PATH = './uncased_L-12_H-768_A-12/bert_config.json'\n",
    "BERT_CONFIG = modeling.BertConfig.from_json_file(BERT_CONFIG_PATH)\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# Fix the seeds\n",
    "random.seed(2314)\n",
    "np.random.seed(1234) \n",
    "tf.set_random_seed(4321) \n",
    "# https://github.com/jkschin/tensorflow/blob/81ebecec7f1952be31d6dd102efd60be5bde968d/tensorflow/docs_src/programmers_guide/non_determinism.md\n",
    "# Results are still not perfectly deterministic because of GPU\n",
    "# Results not even deterministic on CPU (something is missing?)\n",
    "\n",
    "# Do not allow parallism on CPU (makes it deterministic?)\n",
    "session_conf = tf.ConfigProto(\n",
    "      intra_op_parallelism_threads=1,\n",
    "      inter_op_parallelism_threads=1,\n",
    "      device_count={'CPU':1}\n",
    "    ) # Only use one CPU thread!\n",
    "# Does not work, still not deterministic\n",
    "\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 5000\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "OUTPUT_DIR = 'BERT_RUN' + str(datetime.now()) + dataset\n",
    "\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "#run_config = tf.contrib.tpu.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    session_config=session_conf, # Only one thread!\n",
    "    tf_random_seed=3241) # Maybe? use different seed for every Fold in Crossval e.g. seed+fold_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenization.validate_case_matches_checkpoint(True, BERT_INIT_CHKPNT)\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "      vocab_file=BERT_VOCAB, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local data\n",
    "train_df, test_df = load_local_data(data_path, dataset)\n",
    "#print(train_df.head())\n",
    "\n",
    "# Create datasets (Only take up to max_seq_length words for memory)\n",
    "\n",
    "train_df = train_df.replace({'label': convert_dict})\n",
    "test_df = test_df.replace({'label': convert_dict})\n",
    "#print(train_df.groupby('label').describe())\n",
    "#print(test_df.groupby('label').describe())\n",
    "train = train_df.sample(frac=1)\n",
    "test = test_df.sample(frac=1)\n",
    "\n",
    "# Use org + response\n",
    "if use_org and use_resp:\n",
    "    # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "    train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                       text_a = x[ORG_COLUMN], \n",
    "                                                                       text_b = x[RESP_COLUMN], \n",
    "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
    "                                                                       text_a = x[ORG_COLUMN], \n",
    "                                                                       text_b = x[RESP_COLUMN], \n",
    "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
    "# Use only org\n",
    "elif use_org:\n",
    "    # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "    train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                       text_a = x[ORG_COLUMN], \n",
    "                                                                       text_b = None, \n",
    "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
    "                                                                       text_a = x[ORG_COLUMN], \n",
    "                                                                       text_b = None, \n",
    "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
    "# Use only resp\n",
    "else:\n",
    "    # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "    train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                       text_a = x[RESP_COLUMN], \n",
    "                                                                       text_b = None, \n",
    "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
    "                                                                       text_a = x[RESP_COLUMN], \n",
    "                                                                       text_b = None, \n",
    "                                                                       label = x[LABEL_COLUMN]), axis = 1)\n",
    "    \n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cross_val:\n",
    "    # Compute # train and warmup steps from batch size\n",
    "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "    model_fn = model_fn_builder(\n",
    "      num_labels=len(label_list),\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "    \"\"\"model_fn = run_classifier.model_fn_builder(\n",
    "        bert_config=BERT_CONFIG,\n",
    "        num_labels=len(label_list),\n",
    "        init_checkpoint=False,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        use_tpu=False,\n",
    "        use_one_hot_embeddings=False)\"\"\"\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "    #estimator = tf.contrib.tpu.TPUEstimator(\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      params={\"batch_size\": BATCH_SIZE})\n",
    "      #train_batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Create an input function for training. drop_remainder = True for using TPUs.\n",
    "    train_input_fn = run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    print(f'Beginning Training!')\n",
    "    current_time = datetime.now()\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    print(\"Training took time \", datetime.now() - current_time)\n",
    "    \n",
    "    test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "    \n",
    "    predictions = estimator.predict(input_fn=test_input_fn)\n",
    "    pred_label = [prediction['labels'] for prediction in predictions]\n",
    "    print(\"Confusion Matrix:\")\n",
    "    conf_mat = confusion_matrix(test['label'].values.astype(int), np.array(pred_label))\n",
    "    print(conf_mat)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    if len(set(test['label'])) == 3:\n",
    "        print(classification_report(test['label'].values.astype(int), pred_label, target_names=[\"attack\", \"support\", \"unrelated\"]))\n",
    "    else: \n",
    "        #print(classification_report(test['label'].values.astype(int), pred_label, target_names=[\"agreement\", \"disagreement\"]))\n",
    "        print(classification_report(test['label'].values.astype(int), pred_label, target_names=[\"attack\", \"support\"]))\n",
    "        #print(classification_report(test['label'].values.astype(int), pred_label, target_names=[\"relation\", \"unrelated\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not cross_val:\n",
    "    test['predictions'] = pred_label\n",
    "    test['correctness'] = test.apply(lambda r: 1 if r['label'] == r['predictions'] else 0, axis=1)\n",
    "    rels = pd.crosstab(test['topic'], [test['label'],test['predictions']], margins=True, colnames=['label', 'prediction'])\n",
    "    rels2 = pd.crosstab(test['topic'], test['correctness'], normalize='index')"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_features, test_features, test, train, target_names):\n",
    "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "    model_fn = model_fn_builder(\n",
    "        num_labels=len(label_list),\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps)\n",
    "    train_input_fn = run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "    test_input_fn = run_classifier.input_fn_builder(\n",
    "        features=test_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "    print(f'Beginning Training!')\n",
    "    print('test labels', test['label'].value_counts())\n",
    "    print('train labels', train['label'].value_counts())\n",
    "    current_time = datetime.now()\n",
    "    estimator = tf.estimator.Estimator(\n",
    "              model_fn=model_fn,\n",
    "              config=run_config,\n",
    "              params={\"batch_size\": BATCH_SIZE})\n",
    "    estimator = estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    predictions = estimator.predict(input_fn=test_input_fn, yield_single_examples=False)\n",
    "    print(predictions)\n",
    "    pred_label = np.array([])\n",
    "    pred_label = [np.append(pred_label, prediction['labels']) for prediction in predictions]\n",
    "    pred_label = np.concatenate(pred_label).ravel()\n",
    "    print(pred_label)\n",
    "    class_rep = classification_report(test['label'].values.astype(int), pred_label, labels= [0,1], target_names=target_names, output_dict=True)\n",
    "    acc = accuracy_score(test['label'].values.astype(int), pred_label)\n",
    "    print(classification_report(test['label'].values.astype(int), pred_label, target_names=target_names))\n",
    "    print(\"Accuracy:\",  acc)\n",
    "    print(\"Training took time \", datetime.now() - current_time)\n",
    "    return (class_rep, acc)\n",
    "\n",
    "def cross_validate(data):\n",
    "    results = []\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train_idx, val_idx in skf.split(data, data['label']):\n",
    "        try:\n",
    "            tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "        except:\n",
    "            # Doesn't matter if the directory didn't exist\n",
    "            pass\n",
    "        tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "        train = data.iloc[train_idx]\n",
    "        test = data.iloc[val_idx]\n",
    "        print(train.shape, test.shape)\n",
    "        # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "        train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                           text_a = x[ORG_COLUMN], \n",
    "                                                                           text_b = x[RESP_COLUMN], \n",
    "                                                                           label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "        test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
    "                                                                           text_a = x[ORG_COLUMN], \n",
    "                                                                           text_b = x[RESP_COLUMN], \n",
    "                                                                           label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "        # Convert our train and test features to InputFeatures that BERT understands.\n",
    "        train_features = run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "        test_features = run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "        results.append(run_training(train_features, test_features, test, train, [\"relation\", \"unrelated\"]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cross_val:\n",
    "\n",
    "    result = cross_validate(train_df.append(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cross_val:\n",
    "    #print(result)\n",
    "    res = np.array(result)[:,0]\n",
    "    result_df = pd.DataFrame(res[0])\n",
    "    for data in res[1:]:\n",
    "        new_data = pd.DataFrame(data)\n",
    "        result_df = result_df.append(new_data)\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    print(result_df.groupby(level=0).agg([np.mean, np.max, np.min]).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(estimator.get_variable_names())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
